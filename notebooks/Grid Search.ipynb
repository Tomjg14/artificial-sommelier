{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more if needed\n",
    "\n",
    "# data loading\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import pandas as pd\n",
    "import os, random\n",
    "from os import listdir\n",
    "\n",
    "# data inspection\n",
    "from collections import Counter\n",
    "\n",
    "# preprocessing\n",
    "import string\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "# Word embeddings\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# clustering\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "\n",
    "# computations\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# visualization\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# data saving\n",
    "import pickle\n",
    "\n",
    "# progress\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# classification\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/winemag-data-130k-v2.json\"\n",
    "\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "dataset = pd.DataFrame.from_dict(json_normalize(data), orient='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pickle.load(open(\"pickle_files/tokens.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = pickle.load(open(\"pickle_files/pos_tags.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tokens'] = tokens\n",
    "dataset['pos_tags'] = pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Content Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT TO NOTE: while Ilja stated that they filtered on content words, they did not mention what content words. Only that they filtered on adjectives, nouns and verbs. These were the tags we thought relate to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isContentWord(pos_tag):\n",
    "    content_tags = [\"JJ\", \"JJR\", \"JJS\", \"NN\", \"NNP\", \"NNS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]\n",
    "    if pos_tag in content_tags:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next piece of code collects all content words in the dataset, not considering if there are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_words = []\n",
    "for i, token_list in enumerate(tokens):\n",
    "    pos_tag_list = pos_tags[i]\n",
    "    for j, word in enumerate(token_list):\n",
    "        pos_tag = pos_tag_list[j]\n",
    "        if isContentWord(pos_tag):\n",
    "            content_words.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the Counter helps to count the content word occurences. Keys are content words, values are counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_counts = Counter(content_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we filter the content words on more than 2 occurences and only append them to filtered_content_words once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210fbd8d7cea407a90ddf4bf0e7dcf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3016091), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_content_words = []\n",
    "for word in tqdm(content_words):\n",
    "    if content_counts[word] > 2:\n",
    "        if not word in filtered_content_words:\n",
    "            filtered_content_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_COUNT = len(np.unique(filtered_content_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "content_word_dict was created to combine a specific index to each content word. Keys are content_words, values are specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_word_dict = {}\n",
    "for i, word in enumerate(filtered_content_words):\n",
    "    content_word_dict[word] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, content_tokens is a list similar to tokens. It contains N lists were N is equal to the number of reviews in the dataset. Each list corresponds to a review, but this time it only contains the content words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e4abff1cae4a1e8471920f9b75d7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=129971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "content_tokens = []\n",
    "for token_list in tqdm(tokens):\n",
    "    filtered_tokens = []\n",
    "    for token in token_list:\n",
    "        if token in content_word_dict:\n",
    "            filtered_tokens.append(token)\n",
    "    content_tokens.append(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['content_tokens'] = content_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dataset['points'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategory(scores):\n",
    "    category_string = []\n",
    "    category_int = []\n",
    "    for score in scores:\n",
    "        score = int(score)\n",
    "        if score < 80:\n",
    "            category_string.append(\"unacceptable\")\n",
    "            category_int.append(0)\n",
    "        elif score >= 80 and score <= 82:\n",
    "            category_string.append(\"acceptable\")\n",
    "            category_int.append(1)\n",
    "        elif score >= 83 and score <= 86:\n",
    "            category_string.append(\"good\")\n",
    "            category_int.append(2)\n",
    "        elif score >= 87 and score <= 89:\n",
    "            category_string.append(\"very good\")\n",
    "            category_int.append(3)\n",
    "        elif score >= 90 and score <= 93:\n",
    "            category_string.append(\"excellent\")\n",
    "            category_int.append(4)\n",
    "        elif score >= 94 and score <= 97:\n",
    "            category_string.append(\"superb\")\n",
    "            category_int.append(5)\n",
    "        elif score >= 98 and score <= 100:\n",
    "            category_string.append(\"classic\")\n",
    "            category_int.append(6)\n",
    "    return category_string, category_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories, labels = getCategory(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['category'] = categories\n",
    "dataset['labels'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute BoW Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpus(tokens):\n",
    "    corpus = []\n",
    "    for token_list in tqdm(tokens):\n",
    "        content_tokens = []\n",
    "        for token in token_list:\n",
    "            if token not in content_counts:\n",
    "                continue\n",
    "            else:\n",
    "                content_tokens.append(token)\n",
    "        doc = \" \".join(content_tokens)\n",
    "        corpus.append(doc)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c97a6c422e640a9b9a15e690a09cfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=129971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = createCorpus(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_vectorizer = CountVectorizer(min_df=2)\n",
    "bow_feature_vector = bag_of_words_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "varieties = dataset['variety'].tolist()\n",
    "wine_count = Counter(varieties)\n",
    "nr_reviews = len(varieties)\n",
    "threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_keys = []\n",
    "for key, item in wine_count.items():\n",
    "    if item < threshold:\n",
    "        filtered_keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "indices = []\n",
    "for v in varieties:\n",
    "    if v in filtered_keys:\n",
    "        indices.append(idx)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Total reviews: 118263\n"
     ]
    }
   ],
   "source": [
    "dataset_filtered = dataset.drop(dataset.index[indices]).copy()\n",
    "dataset_filtered = dataset_filtered.reset_index()\n",
    "\n",
    "print(\"New Total reviews: %s\"%(len(dataset_filtered)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines = np.unique(dataset_filtered['variety'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_indices = {}\n",
    "for wine in wines:\n",
    "    indices = dataset_filtered.index[dataset_filtered['variety'] == wine].tolist()\n",
    "    wine_indices[wine] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = {}\n",
    "test_indices = {}\n",
    "for wine in wines:\n",
    "    indices = wine_indices[wine]\n",
    "    nr_indices = len(indices)\n",
    "    train_indices[wine] = indices[:round(nr_indices*0.8)]\n",
    "    test_indices[wine] = indices[round(nr_indices*0.8):]\n",
    "    \n",
    "    nr_train_indices = len(indices[:round(nr_indices*0.8)])\n",
    "    nr_test_indices = len(indices[round(nr_indices*0.8):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_indices = []\n",
    "for _, indices in train_indices.items():\n",
    "    tr_indices = tr_indices + indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_indices = []\n",
    "for _, indices in test_indices.items():\n",
    "    t_indices = t_indices + indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dataset_filtered.iloc[tr_indices,:].copy()\n",
    "testset = dataset_filtered.iloc[t_indices,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(train_features,train_labels,test_features):\n",
    "    clf = SVC(kernel='rbf', verbose=True)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    print(\"\\ndone fitting classifier\\n\")\n",
    "    return clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true,y_pred):\n",
    "    recall = sklearn.metrics.recall_score(y_true, y_pred, average='macro')\n",
    "    print(\"Recall: %f\" % recall)\n",
    "\n",
    "    precision = sklearn.metrics.precision_score(y_true, y_pred, average='macro')\n",
    "    print(\"Precision: %f\" % precision)\n",
    "\n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    print(\"F1-score: %f\" % f1_score)\n",
    "\n",
    "    return recall, precision, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_features,train_data,test_features,test_data):\n",
    "    train_labels = train_data['labels'].tolist()\n",
    "\n",
    "    test_labels = test_data['labels'].tolist()\n",
    "        \n",
    "    y_pred = classify(train_features,train_labels,test_features)\n",
    "        \n",
    "    recall, precision, f1_score = evaluate(test_labels, y_pred)\n",
    "    \n",
    "    print(\"recall: %s\"%(recall))\n",
    "    print(\"precision: %s\"%(precision))\n",
    "    print(\"f1 score: %s\"%(f1_score))\n",
    "    \n",
    "    return recall, precision, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14a8638883f47268783cd8c1ae2425f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=94614), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_tokens = trainset['tokens'].tolist()\n",
    "train_corpus = createCorpus(train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = bag_of_words_vectorizer.transform(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4267a09e22e2499584636d80a837e5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23649), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_tokens = testset['tokens'].tolist()\n",
    "test_corpus = createCorpus(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = bag_of_words_vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-20 21:19:00.742128\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(start)\n",
    "recall, precision, f1_score = main(train_features,trainset,test_features,testset)\n",
    "end = datetime.now()\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = trainset.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbce646852e14e27be7be29b8561b8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random_tokens = random_sample['tokens'].tolist()\n",
    "random_corpus = createCorpus(random_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_features = bag_of_words_vectorizer.transform(random_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_labels = random_sample['labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':['rbf'], 'C': np.arange(1,40,2), 'gamma': np.linspace(0.0, 0.2, 11)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(svc, parameters, verbose=10, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 220 candidates, totalling 660 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed: 34.3min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed: 36.5min\n",
      "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed: 38.9min\n",
      "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed: 41.5min\n",
      "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed: 47.1min\n",
      "[Parallel(n_jobs=4)]: Done 660 out of 660 | elapsed: 48.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'kernel': ['rbf'], 'gamma': array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ]), 'C': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
       "       35, 37, 39])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(random_features,random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'gamma': 0.02, 'C': 5}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
